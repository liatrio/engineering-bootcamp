---
docs/3-AI-Engineering/3.1.4-ai-best-practices.md:
  category: AI Engineering
  estReadingMinutes: 30
---

# Best Practices for AI Engineering

AI is a major asset in increasing the velocity of engineering tasks. It also, however, requires a level of care and purposeful application to ensure that the output is of high quality and aligns with the goals of the project.

This section will outline some best practices for using AI tools in your development workflow so you can utilize it effectively while avoiding common pitfalls.

## AI Best Practices

- Do not blindly use code that it gives you. Take time to read through any examples you are given and understand what it does. The AI model may not be using up-to-date information when it is helping you, or can even hallucinate nonexistent code as truth, so you should only trust code that you are able to back up with your own knowledge or by checking against relevant documentation.
- To get more accurate information, specify any context that you want the bot to have. The more information it has, the better results it will be able to return for your use case. This includes providing relevant code snippets, error messages, desired outcomes, and constraints.
- Be aware that chat tools are not always reliable, and the results of what it gives you are never guaranteed. You should never let AI have the final say on handling sensitive or valuable information or infrastructure.
- **Manage context window utilization proactively.** As conversations with AI assistants grow longer, they accumulate context that can lead to performance degradation—a phenomenon called "context rot." Research shows that when context window utilization exceeds 40%, LLM performance degrades significantly, with reasoning capabilities declining and hallucinations increasing. This happens because the model struggles to effectively process and prioritize information when the context becomes too full. To combat this, apply **intentional compaction** when you notice context utilization approaching 60% or when responses become less accurate. Compaction involves distilling your conversation into essential information, starting a fresh chat with a concise summary, and progressively loading only the context needed for your current task. This practice maintains AI effectiveness throughout longer development sessions while preventing the "dumb zone" that emerges in overloaded context windows.
- Be aware of what these tools are doing with your data. You should only use tools that will use your data ethically. Some organizations may prohibit the use of AI tools entirely, or only use internal chat bots, to protect the integrity of potentially sensitive data that they are handling. Always check your organization's policy.
- AI is only as smart as the internet it is trained on. Chat bots are essentially just a powerful, opinionated google search, and can only give you information from someone on the internet, but likely will not be able to check the validity of the claims it gives you. It is a good habit to verify anything you get from a chat bot before deciding to use it.

## Understanding Context Windows

When you interact with an AI assistant, everything in your conversation—your messages, the AI's responses, any code or documents you share—gets stored in what's called a **context window**. Think of this as the AI's working memory for your conversation.

### What Are Context Windows?

A context window is the total amount of information (measured in tokens) that an AI model can consider at once. Different AI models have different context window sizes:

- **Smaller models**: 8,000-16,000 tokens (roughly 6,000-12,000 words)
- **Medium models**: 32,000-64,000 tokens (roughly 24,000-48,000 words)
- **Large models**: 128,000-200,000+ tokens (roughly 96,000-150,000+ words)

A token is approximately 3-4 characters of text, so "Hello, world!" is about 3-4 tokens. Code tends to use more tokens than plain text because of syntax characters and formatting.

### How LLMs Process Context

When you send a message to an AI assistant, the model processes your entire conversation history plus your new message. The model:

1. **Reads the full context** from beginning to end
2. **Identifies patterns and relationships** between different parts of the conversation
3. **Generates a response** based on all available context
4. **Adds the response** to the context window for future messages

This means each message you send requires the model to re-process everything that came before it. As your conversation grows, this processing becomes more complex and resource-intensive.

### Why This Matters for AI-Assisted Development

Understanding context windows is crucial for effective AI-assisted development because:

- **Context fills up quickly** when working with code. A single medium-sized file can consume thousands of tokens. Copying multiple files, error logs, or documentation into a conversation can exhaust the context window surprisingly fast.
- **Performance degrades as context grows** (see next section on context rot). Once you exceed certain thresholds, the AI's ability to reason effectively diminishes.
- **You can't add context indefinitely**. Eventually you'll hit the model's limit, and older messages will be truncated or lost entirely.
- **Context management becomes a skill**. Learning to provide the right context at the right time—neither too much nor too little—is essential for productive AI collaboration.

Effective context management means understanding when to start fresh conversations, when to compact existing context, and how to structure your interactions to maintain AI effectiveness throughout your development session.

## Context Rot and Performance Degradation

As your conversation with an AI assistant grows longer, you may notice the responses becoming less accurate, more confused, or prone to hallucinations. This phenomenon is called **context rot**, and it's one of the most important challenges to understand in AI-assisted development.

### What Is Context Rot?

Context rot occurs when an AI model's performance degrades as the context window fills up. Even though modern AI models have large context windows (100k+ tokens), research from Chroma and others has shown that models become significantly less effective as context utilization increases—particularly when exceeding certain thresholds.

### The 40% "Dumb Zone"

Research has identified a critical threshold: **when context window utilization exceeds 40%, LLM reasoning capabilities begin to degrade noticeably**. This degradation manifests as:

- **Increased hallucinations**: The model starts fabricating details or "remembering" things that weren't actually in the context
- **Reduced reasoning ability**: Complex problem-solving becomes less reliable
- **Context confusion**: The model may conflate different parts of the conversation or lose track of what's been discussed
- **Instruction following deterioration**: The model becomes less consistent at following your instructions

Some research suggests that models can effectively handle approximately **150-200 high-quality instructions** before performance degradation becomes significant. Once you've exceeded this threshold, you're operating in what practitioners call the "dumb zone"—where the AI still responds but with noticeably reduced effectiveness.

### Real-World Symptoms You'll Encounter

As you work with AI assistants throughout this bootcamp and beyond, watch for these warning signs of context rot:

- **Repetitive suggestions**: The AI starts repeating the same advice or code patterns it already provided
- **Loss of context awareness**: The AI forgets decisions or constraints you established earlier in the conversation
- **Increased verbosity**: Responses become unnecessarily long or circular as the model struggles to focus
- **Code regression**: New code suggestions break patterns or functionality that were working earlier
- **Contradictory advice**: The AI provides guidance that conflicts with its earlier recommendations

### Why Context Rot Happens

Context rot occurs because:

1. **Attention mechanisms have limits**: The model must distribute its "attention" across the entire context. As context grows, attention becomes more diffuse, making it harder to focus on what's most important.
2. **Signal-to-noise degradation**: Early in a conversation, nearly everything is relevant. As context accumulates, irrelevant details (dead-end explorations, discarded approaches, tangential discussions) create noise that obscures the signal.
3. **Computational constraints**: Processing longer contexts requires more compute resources and time, which can lead to shortcuts or approximations that reduce quality.

Understanding context rot is the first step toward managing it effectively. The next sections will cover practical techniques for preventing and recovering from context rot during your development sessions.

## Intentional Compaction Techniques

Rather than letting context rot sneak up on you, professional AI-assisted development requires **intentional compaction**—the practice of deliberately distilling and resetting context to maintain AI effectiveness throughout long development sessions.

### What Is Intentional Compaction?

Intentional compaction is the process of:

1. **Recognizing** when context has become cluttered or is approaching critical thresholds
2. **Distilling** the essential information from your current conversation
3. **Starting fresh** with a new conversation that includes only the necessary context
4. **Continuing work** with restored AI effectiveness

Think of it as "checkpointing" your conversation—you're preserving what matters while discarding the noise that's degraded performance.

### When to Trigger Compaction

You should consider compacting context when:

- **Context utilization exceeds 60%**: This gives you a buffer before hitting the 40% degradation zone (since context continues growing with each exchange)
- **AI responses degrade noticeably**: You observe the symptoms of context rot discussed in the previous section
- **Transitioning between work phases**: Moving from research to planning, or planning to implementation, is a natural compaction point
- **Before critical tasks**: If you're about to tackle a complex problem, start with a clean context window

Many AI tools provide context indicators or commands (like `/context` in Claude Code) that help you monitor utilization and make informed compaction decisions.

### Compaction Strategies

Different situations call for different compaction approaches:

#### Research → Plan → Implement Pattern

This three-phase approach naturally structures compaction:

1. **Research Phase**: Use AI to explore the codebase, understand patterns, and gather information. Context grows rapidly as you load files and documentation.

2. **Compaction & Planning Phase**: Start a fresh conversation with a summary of your research findings. Ask the AI to help create an implementation plan based on this distilled context. The plan serves as your compacted context.

3. **Implementation Phase**: Start another fresh conversation with the plan as your primary context. Progressively load only the specific files you're currently modifying, keeping context lean and focused.

#### The Summary-and-Reset Pattern

For simpler tasks:

1. Ask the AI to summarize the current state: "Please summarize what we've accomplished, what we're currently working on, and what remains to be done."
2. Copy this summary
3. Start a new conversation with: "Context: [paste summary]. Let's continue with [next task]."

#### The Checkpoint Pattern

For complex, multi-day projects:

1. At the end of each work session, create a checkpoint document (e.g., `WORKING_NOTES.md`)
2. Include: current state, decisions made, next steps, relevant file paths
3. Start each new session by loading this checkpoint document
4. Update the checkpoint as you progress

### Practical Examples

**Example 1: Compacting During Bug Investigation**

Instead of:
```text
[150+ messages of debugging, log analysis, hypothesis testing]
"The AI is now confused and suggesting things we already tried"
```

Apply compaction:
```text
New conversation: "I'm investigating a bug where user authentication fails intermittently.
Through testing I've determined: [3-bullet summary of findings].
The relevant code is in auth/login.ts:45-67 [provide file].
Help me identify the root cause and fix."
```

**Example 2: Compacting When Switching Phases**

After research phase:
```text
New conversation: "I'm implementing a new feature: [brief description].
Based on codebase analysis, I should: [3-4 key patterns to follow].
The relevant files are: [list with brief descriptions].
Let's start by creating a specification for this feature."
```

### Tips for Effective Compaction

- **Be ruthless about what to keep**: If something didn't lead anywhere useful, leave it behind
- **Preserve decisions and constraints**: These are critical context that should survive compaction
- **Use file:line references**: Instead of copying entire files, reference them (e.g., "see auth.ts:23-45") and load them on-demand
- **Document as you go**: Keeping brief notes makes compaction easier and faster
- **Practice regularly**: Compaction is a skill that improves with deliberate practice

Intentional compaction transforms AI assistance from a sprint (which degrades after 150-200 instructions) into a marathon where you maintain effectiveness indefinitely.

## Progressive Disclosure Patterns

While intentional compaction helps you manage existing context, **progressive disclosure** is a complementary strategy that prevents context bloat in the first place. Progressive disclosure means providing context to the AI incrementally—loading information on-demand as it becomes relevant rather than front-loading everything at the start.

### Front-Loading vs. On-Demand Context

**Front-loading approach** (less effective):
```text
[Message 1]
Here's the entire codebase structure... [5000 tokens]
Here are all the relevant files... [10000 tokens]
Here's the documentation... [3000 tokens]
Now help me fix this small bug in auth.ts
```

**Progressive disclosure approach** (more effective):
```text
[Message 1]
I need to fix a bug in auth.ts where login fails. Here's the error: [error message]

[Message 2]
[After AI asks] Here's the relevant auth.ts code: [specific function]

[Message 3]
[After AI asks] Here's how we call it from login.ts:45-67
```

Progressive disclosure keeps context lean, ensures the AI focuses on what's immediately relevant, and gives you headroom to go deeper when needed.

### Structuring Project Context Files

Many AI tools let you provide project-level context through files like `CLAUDE.md`, `.cursorrules`, or similar configuration. These files are powerful but can quickly bloat context if not structured carefully.

**Effective project context file structure:**

1. **Overview section** (100-200 tokens): Brief project description, architecture, and key patterns
2. **Command reference** (50-100 tokens): Essential commands (build, test, lint)
3. **File pointers** (200-300 tokens): Map features to files without including file contents
4. **Conventions** (100-200 tokens): Code style, naming patterns, testing approaches

**Example of file pointer instead of full file:**

Instead of:
```markdown
## Authentication Module
[Paste entire auth.ts file - 2000 tokens]
```

Use:
```markdown
## Authentication Module
- Login logic: `src/auth/login.ts:23-45` (JWT-based)
- Session management: `src/auth/session.ts:12-67` (Redis-backed)
- User validation: `src/auth/validators.ts` (Zod schemas)
```

When the AI needs the actual code, it can request specific files or line ranges, keeping baseline context lean.

### File:Line References Over Code Copying

Get in the habit of referencing code locations rather than copying entire files:

**Less effective:**
```text
"Here's the entire UserService class:" [paste 500 lines]
```

**More effective:**
```text
"The issue is in UserService.findById() at src/services/user.ts:89-103"
[Then provide just those lines if the AI asks]
```

This approach:
- Keeps context focused on what's relevant
- Makes it easier for you to verify what the AI is looking at
- Allows the AI to request additional context if needed
- Prevents context bloat from peripheral code

### Avoiding Context Bloat

Context bloat happens when you inadvertently load unnecessary information. Common sources:

- **Error dumps**: Posting entire stack traces when the key error is in the first 3 lines
- **Log files**: Sharing 1000 lines of logs instead of the relevant 20 lines
- **Documentation**: Pasting entire API docs when you only need one endpoint
- **Test files**: Loading all tests when you're debugging one specific failure

**Practice selective context loading:**

1. **Start minimal**: Provide only what's needed for the immediate question
2. **Let AI request more**: If the AI needs additional context, it will ask
3. **Summarize when possible**: Instead of raw data, provide structured summaries
4. **Use links**: For documentation, provide URLs instead of full-text copies

### Practical Progressive Disclosure Workflow

Here's how progressive disclosure might look in practice:

```text
[Phase 1: Problem statement - 50 tokens]
"I need to add rate limiting to our API endpoints"

[Phase 2: Architecture context - 200 tokens]
[After AI asks about current setup]
"We use Express.js, middleware pattern, see middleware/index.ts for examples"

[Phase 3: Specific implementation - 500 tokens]
[After AI proposes approach]
"Here's our current authentication middleware: [paste relevant code]"

[Phase 4: Testing context - 300 tokens]
[During implementation]
"Here's how we test middleware: [paste test example]"
```

Total context used: ~1050 tokens, loaded progressively as needed, each piece directly relevant to the current step.

Compare to front-loading everything: ~3000+ tokens, most unused, increased noise-to-signal ratio.

### Tips for Effective Progressive Disclosure

- **Answer questions precisely**: When the AI asks for context, provide exactly what it requested—no more, no less
- **Trust the AI to ask**: Modern AI assistants are good at identifying what context they need
- **Use project context files wisely**: Keep them lean and pointer-heavy rather than content-heavy
- **Develop a mental model**: Think of context as a scarce resource to be allocated strategically
- **Combine with compaction**: Progressive disclosure prevents bloat; compaction fixes it when it happens

Progressive disclosure is preventive medicine for context rot. By loading context deliberately and incrementally, you maintain AI effectiveness from the start rather than fighting degradation later.

## Tracking Context Utilization

To effectively manage context, you need visibility into how much of your context window is being used. Most modern AI development tools provide mechanisms for monitoring context utilization, allowing you to make informed decisions about when to compact or start fresh.

### Claude Code: /context Command

Claude Code provides a built-in `/context` command that displays current context utilization:

```bash
/context
```

This command returns:
- Total tokens used
- Percentage of context window filled
- Breakdown of context sources (messages, files, system instructions)

**How to use it:**
- Check context before starting complex tasks
- Monitor context when approaching the 40-60% range
- Verify context after compaction to ensure it was effective

### VSCode AI Tools: Context Indicators

Many VSCode AI extensions provide visual context indicators:

- **GitHub Copilot Chat**: Shows token count in the chat interface
- **VSCode status bar indicators**: Some extensions display context usage in the bottom status bar
- **Extension-specific commands**: Check your AI extension's documentation for context monitoring commands

### Other AI Assistant Tools

Different AI tools provide varying levels of context visibility:

- **Cursor**: Built-in context viewer showing token usage and file inclusions
- **Windsurf**: Context tracking in the Cascade interface
- **ChatGPT/Claude web interfaces**: Some show conversation length, though less precise than developer tools

### Manual Context Estimation

If your tool doesn't provide precise context tracking, you can estimate:

- **Message count heuristic**: Roughly 150-200 high-quality back-and-forth exchanges before hitting degradation zones
- **File inclusion tracking**: Keep a mental note of how many files you've loaded (each medium file is ~2000-5000 tokens)
- **Response quality monitoring**: Watch for the symptoms of context rot discussed earlier

### Establishing Context Monitoring Habits

Develop these habits for effective context monitoring:

1. **Check before critical tasks**: Always verify context utilization before important work
2. **Set utilization thresholds**: Decide on your compaction triggers (e.g., "compact at 60%")
3. **Monitor during long sessions**: Check context periodically during extended development sessions
4. **Post-compaction verification**: After compacting, verify that context was successfully reduced
5. **Tool-specific learning**: Learn your specific tool's context monitoring features and make them part of your workflow

### Context Utilization Red Flags

Beyond tool indicators, watch for these behavioral red flags that suggest high context utilization even if metrics aren't available:

- Responses taking noticeably longer to generate
- The AI repeating itself or providing circular advice
- Decreased accuracy or increased hallucinations
- The AI losing track of earlier decisions or constraints
- Your own confusion about what context the AI is working with

When you observe these patterns, it's time to compact regardless of what metrics show (or don't show).

### Practical Context Monitoring Workflow

Here's a typical workflow incorporating context monitoring:

```text
[Starting a new feature]
1. /context → 5% utilization (clean slate)

[After research phase]
2. /context → 35% utilization (approaching watch zone)
3. Decision: Compact before planning phase

[After compaction & planning]
4. /context → 12% utilization (successfully compacted)

[During implementation]
5. /context → 45% utilization (in watch zone)
6. Continue working, monitoring closely

[Before testing complex edge case]
7. /context → 63% utilization (above threshold)
8. Decision: Compact before proceeding

[After compaction]
9. /context → 15% utilization (ready for testing)
```

By making context monitoring a regular practice, you transform context management from reactive problem-solving into proactive engineering discipline.

## Resources and Further Reading

This section provides links to deeper explorations of context engineering, AI-assisted development best practices, and research that informs these approaches.

### Context Engineering and AI Development Methodologies

- **[12-Factor Agents](https://www.humanlayer.dev/12-factor-agents)** - HumanLayer's comprehensive methodology for building reliable AI agent applications, covering architectural principles that extend beyond individual coding sessions to production AI systems.

- **[Advanced Context Engineering for Coding Agents](https://github.com/humanlayer/advanced-context-engineering-for-coding-agents)** - Deep dive into context engineering techniques specifically for AI-assisted coding, including detailed coverage of Research-Plan-Implement workflows and intentional compaction strategies.

- **[Writing a Good CLAUDE.md](https://www.humanlayer.dev/blog/writing-a-good-claude-md)** - Practical guide to structuring project context files using progressive disclosure principles, showing how to provide AI assistants with effective project-level context without bloating the context window.

- **[A Brief History of Ralph](https://www.humanlayer.dev/blog/brief-history-of-ralph)** - Explores context carving and fresh context window techniques developed through real-world AI-assisted development experience.

### Research and Performance Studies

- **[Chroma Research: Context Rot Study](https://research.trychroma.com/context-rot)** - Scientific analysis of LLM performance degradation as context length increases, providing the research foundation for the 40%+ degradation threshold discussed in this chapter.

- **[Anthropic: Effective Context Engineering for AI Agents](https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents)** - Official guidance from Anthropic (creators of Claude) on context engineering best practices, covering both technical mechanisms and practical strategies.

### Recommended Reading Order

If you're new to context engineering, we recommend reading in this order:

1. Start with this bootcamp chapter to build foundational understanding
2. Review "Writing a Good CLAUDE.md" for practical application to your projects
3. Explore "Advanced Context Engineering" for deeper technical techniques
4. Read "12-Factor Agents" when you're ready to think about production AI systems
5. Consult research papers when you want to understand the underlying mechanisms

These resources will deepen your understanding of the context engineering principles introduced in this chapter and help you develop sophisticated context management practices as you progress in your AI-assisted development journey.

## Deliverables

- Consider some potential pitfalls of using AI tools in your development workflow, and how you can avoid them.
- Think of ways you can utilize AI enhanced development to make your work more efficient.
- What are the warning signs of context rot, and at what context utilization threshold does performance typically begin to degrade?
- Describe a situation in your work where you would apply intentional compaction. What would you preserve, and what would you discard?
- How does progressive disclosure differ from front-loading context? When would you choose one approach over the other?
- What tools or techniques would you use to monitor context utilization in your preferred AI assistant?
- While working through the rest of the chapter—and the rest of the Bootcamp as a whole—be conscientious of patterns that improve or worsen AI driven engineering.
